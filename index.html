<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Junhua Liu</title>
  
  <meta name="author" content="Junhua Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="u8S0zPtl4mCVVwZ0YUFtVrgQnq9eBhl9N4W83xsN0xw" />
  <link type="image/png" sizes="32x32" rel="icon" href="images/doge.jpg">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
		<table style="border-radius:30px;margin-top:5px;margin-bottom:15px;background-color:#e9ecef;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
		<tbody>
          <tr style="padding:0px"> 
            <td style="padding:2.5%;width:70%;vertical-align:middle">
              <p style="text-align:center">
                <name>Junhua Liu<sup><a href="https://www.name-coach.com/kevin-joo" style="font-size:10px;margin-top:10px;position:absolute;">[?]</a></sup></name>
              </p>
			  <p style="text-align:center">
				&nbsp|&nbsp
				<a href="#news" onclick=Expand("news")>News</a>
				&nbsp|&nbsp
				<a href="#publication" onclick=Expand("publications")>Publications</a>
				&nbsp|&nbsp
				<a href="#talks" onclick=Expand("experience")>Talks</a>
				&nbsp|&nbsp
				<a href="#mis" onclick=Expand("experience")>Miscellaneous</a>
				&nbsp|&nbsp
				<a href="#projects" onclick=Expand("projects")>Projects</a>
				&nbsp|&nbsp
				<a href="mailto:jeshualiu@gmail.com">Contact</a>
				&nbsp|&nbsp
	  </p>
		<p>
			Undergraduate Student <br><a href="https://sds.cuhk.edu.cn/" target="_blank">School of Data Science</a><br><a href="https://cuhk.edu.cn/" target="_blank">The Chinese University of Hongkong, Shenzhen</a> <br>
			 Research assistant at <a href="https://fnii.cuhk.edu.cn/">FNii</a>; Research intern at <a href="https://sensetime.com/">Sensetime </a> <br>
			 <span ismodified="1" class="br_wrap"> Second Floor, Zhixin Building, CUHK(SZ), Shenzhen, Guangdong, China, 518172<span><br>
			Email1: junhualiu at cuhk dot edu dot en, &nbsp  Email2: jeshualiu at gmail dot com
		</p>
	<p>I am currently a thrid-year B.S. student at <a href="https://www.cuhk.edu.cn/" target="_blank">CUHK, Shenzhen,</a> where I am supervised by <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html" target="_blank">Prof. Fangxin Wang</a>. I also intern at SenseTime Research supervised by <a href="https://air.tsinghua.edu.cn/info/1046/1555.htm" target="_blank">Prof. Yan Wang.</a> 
	My broad interest lies at the intersection of computer network, omnidirectional vision and robot learning with a current focus on emerging AR/VR applications.
	</p>
	<brief>Previously, I have been fortunate enough to have opportunities to conduct research on HCI at Harvard CAMLab and dialogue system at AIRS NLP group. I also lucky to learn research from <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en" target="_blank" style="font-size:10px">Prof. Shuguang Cui</a>, <a href="http://hxu.rocks/" target="_blank" style="font-size:10px">Prof. Huazhe Xu</a>, <a href="https://zachzeyuwang.github.io/" target="_blank" style="font-size:10px">Prof. Zeyu Wang</a>, <a href="https://scholar.google.com/citations?user=MsRp7g0AAAAJ&hl=zh-CN" target="_blank" style="font-size:10px">Prof. Yan Song.</a></p></brief>
              <p style="text-align:center">
                <a href="mailto:jeshualiu@gmail.com">Email</a> &nbsp/&nbsp
                <a href="images/Junhua Liu_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com">Google Scholar</a> &nbsp/&nbsp
				<a href="https://github.com/junhualiu0">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/Junh_Liu">Twitter</a> &nbsp/&nbsp
				<a href="images/Junhua Liu_CV.pdf">Research Statement</a> &nbsp/&nbsp
				<a href="junhualiu.ml">Blog</a> &nbsp/&nbsp						
              </p>

            </td>
			<td style="padding:2.5%;width:20%;max-width:20%">
                    <!--Slide Ref: https://www.youtube.com/watch?v=0wvrlOyGlq0-->
                    <div id="myslides" class="slider">
                      <div class="slides">
                        <input type="radio" name="radio-btn" id="radio1">
                        <input type="radio" name="radio-btn" id="radio2">
                        <input type="radio" name="radio-btn" id="radio3">
						<input type="radio" name="radio-btn" id="radio4">
                        <div class="slide first">
                          <img src="images/pic.jpg" style="width:80%;height:50%;max-width:80%; pointer-events: none" alt="">
                        </div>
                        <div class="slide">
                          <img src="images/pic3.png" style="width:80%;height:50%; max-width:80%; pointer-events: none" alt="">
                        </div>
                        <div class="slide">
                          <img src="images/pic2.png" style="width:80%;height:50%; max-width:80%; pointer-events: none" alt="">
                        </div>
                        <div class="slide">
                          <img src="images/pic4.png" style="width:80%;height:50%; max-width:80%; pointer-events: none" alt="">
                        </div>
                        <div class="navigation-auto">
                          <div class="auto-btn1"></div>
                          <div class="auto-btn2"></div>
                          <div class="auto-btn3"></div>
                          <div class="auto-btn4"></div>						  
                        </div>
                        
                        <div class="navigation-manual">
                          <label for="radio1" class="manual-btn"></label>
                          <label for="radio2" class="manual-btn"></label>
                          <label for="radio3" class="manual-btn"></label>
                          <label for="radio4" class="manual-btn"></label>						  
                        </div>

                        <script type="text/javascript">
                          document.getElementById("radio1").checked = true;

                          let counter = 1;

                          setInterval(() => {
                            document.getElementById("radio" + ((counter % 3) + 1)).checked = true;
                            counter++;
                          }, 7500);
                        </script>
                      </div>
                    </div>
                    <!-- <a href="images/ny-circle.png" style="pointer-events: none"><img style="width:100%; max-width:100%; pointer-events: none" alt="profile photo" src="images/ny-circle.png" class="hoverZoomLink"></a> -->
                  </td>
          </tr>
        </tbody></table>


		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading id="news">News</heading>
			<div style="height:170px;width:800px;overflow:auto;">
			<p>📌I am looking for Summer Research in 2023 Summer, feel free to contact me.</p>
			<details><summary>📌WeChat Group for 2024 fall CS/DS MS/PHD Application are available.</summary>		
			<p style="color:#FF0000" ;="">Welcome to join 2024 fall CS/DS/Stat MS/PhD applications group, please add group manager, WeChat: doubleliu0523, to join the group.</p></details>
			<p>[12.2022] One paper was accepted by IEEE VR 2023 as first author</p>
			<p>[06.2022] I joined the Video [Code]C group in SenseTime Research Institute as a Research Intern.</p>
			<p>[06.2022] One paper was accepted by ACM MM 2022 as co-first author</p>
			<p>[12.2021] One paper was accepted by IEEE VR 2022 as short paper.</p>
			<p>[03.2022] I joined the Harvard Univ. as a Research Assistant.
			<p>[09.2021] I joined the Intelligent Networking and Multimedia Lab as a Research Assistant.
			<p>[07.2021] I joined NLP Lab in AIRS as a Research Assistant.
			</div>
            </td>
          </tr>
		
	
		
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="width:100%;vertical-align:middle;padding-left:20px">
              <heading id="publication">Publication & Project</heading> <br>
                    <a href="#journal" target="_self">Journal/</a>
                    <a href="#conference" target="_self">Conference/</a>
					<a href="#projects" target="_self">project/</a>
					<a href="#scholar.google.com" target="_self">Full paper list</a> <br>
			<brief>My research interest lies at the computer network and systems, with intersection over multimedia, human-computer interaction, and robot learning. <br>
			<b>Description:</b> The next generation of real-time interactive multimedia, such as metaverse, virtual reality, and videoconferencing, requires much more bandwidth and computation than current applications. However, the underlying system and algorithm design is not sufficient to provide a satisfactory, low latency experience for multiple users. In my research, I have three goals:
			<b>(1) Networked VR system:</b> To overcome the hardware limitations of current devices, I am working on building a next-generation streaming system for mobile augmented/mixed reality, multi-user extended reality, and the metaverse that can be supported on commodity mobile devices. 
			<b>(2) ML for networked systems:</b> Exploiting new perspective of applying machine learning techniques to improve the performance and reliability of large-scale networked systems. 
			<b>(3) Video Streaming and Compression:</b> For emerging 360-degree /holographic/ volumetric video, we are researching ways to stream them in real-time, focusing on the networking challenges that come with it. We are also using deep neural compression to efficiently transmit high-dimensional video data and display high-quality 3D content on devices with limited resources.
			<b>(4) Spatial Computing:</b> By understanding and perceiving the dynamics of the multimodal world and human priors, we use optimization techniques such as on-device and edge-assisted collaborative caching and streaming to reduce overhead. We are also working on providing accurate and robust tracking of multiple agents for various tasks and generating their avatars for multi-user XR.

			</brief>
			</td> 
          </tr>

    </tbody></table>
		
		
		
		
<!-- Journal		 -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-left:10px"><tbody>
				  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">                     
			<heading id="journal">Journal</heading>
                    </td>
                    </td></tr>
                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                        <img src="images/trans.png" width="80">
                    </td>
                    <td style="padding:0px;width:85%;vertical-align:middle;padding-top:0px;padding-bottom:0px;padding-left:10px">
                      <strong>A Networking Perspective of Volumetric Videos: Opportunities and Challenges</strong>
                      <br>
					  Other author</span>
<!--                       <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
					  <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Boxiang Zhu</span></a>,
					 <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Wenyi Zhang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Zihan Xu</span></a>,
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>, -->
                      <br><span ismodified="1" class="br_wrap">
                       </span><em><span ismodified="1" class="br_wrap">Submitted to Magazine</span></em>, 2022.
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Ebublio: Edge Assisted Multi-user 360-Degree Video Streaming</span></strong> <br>
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span><sup></sup></strong>, 
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      Expansion of conference version.</span><em><span ismodified="1" class="br_wrap"> Minor Revision (JCR Q1)</span></em>, 2022.
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Melt: Streaming Neural Fields-Enhanced Volumetric Video on Mobile Architectures.</span></strong> <br>
					  First author,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">Expansion of conference version</span></em>, 2023. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>					  
				<br>
               </tbody>
              </table>
			  <!-- † -->



<!-- Conference -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-left:10px"><tbody>
			<heading id="conference" style="padding-left:20px">Conference</heading>
			
                  <tr bgcolor="#ffffe6">
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Neural Fields for Networking: Advances, Opportunities and Outlook</span></strong> <br>
					  First author,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">Manuscript and arXiv coming soon</span></em>, 2023. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>					
			
                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">A Volumetric Video Dataset for Daily Scenarios</span></strong> 
                      <br>

                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Kaiyuan Hu</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Haowen Yang</span></a>,
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 					  
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>,
<!--                       <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
					  <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Boxiang Zhu</span></a>,
					 <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Wenyi Zhang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Zihan Xu</span></a>,
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>, -->
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em>, 2023. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>	
				  
                  <tr bgcolor="#ffffe6">
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Melt: Implicit Neural Representation-Enhanced Volumetric Video Streaming on Mobile Devices</span></strong> <br>
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yuanyuan Wang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yan Wang</span></a>,
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em>, 2023. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>
				 		  
                  <tr bgcolor="#ffffe6">
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">CaV3: Cache-assisted Viewport Adaptive Volumetric Video Streaming</span></strong> <br>
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Boxiang Zhu</span></a>,
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Wenyi Zhang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Zihan Xu</span></a>,
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span>Conditionally accepted for presentation and publication at<em><span ismodified="1" class="br_wrap"> (IEEE VR)</span></em>, 2023. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>
				  
<!--                   <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap"> A Dataset for Exploring Social XR in Volumetric Video Streaming</span></strong> <br>

                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Kaiyuan Hu</span></a>,

                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
					                        <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 											
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em> 2022. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      <br>
                      <span ismodified="1" class="br_wrap">PDF</span> /
                      <span>Project Page</span>
                      <p></p>
                    </td>
                  </tr>
                  <tr> -->
			  
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Efficient NeRF: Utilizing Efficient Neural Radiance Fields for Downstream Applications</span></strong> <br>
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Biaolin Wen</span></a>,
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Rui He</span></a>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yuanyuan Wang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yan Wang</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Hongwei Qin</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em>, 2022. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      <span ismodified="1" class="br_wrap">[PDF]</span> 
                      <span>[Project Page]</span>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                        <img src="images/trans.png" width="80">
                    </td>
                    <td style="padding:0px;width:85%;vertical-align:middle;padding-top:0px;padding-bottom:0px;padding-left:10px">
                      <strong>Where Are You Looking? A Large-Scale Dataset of Head and Gaze Behavior for 360-Degree Videos and a Pilot Study.</strong>
                      <br>
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin*</span></a>,
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu*</span></strong>, 
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      ACM Multimedia (</span><em><span ismodified="1" class="br_wrap">MM</span></em>), 2022.
                      <a href=""><span ismodified="1" class="br_wrap">[arXiv]</span></a>
                      <a href="https://junhualiu0.github.io"><span ismodified="1" class="br_wrap">[Project Page]</span></a>
                      <a href="https://github.com/junhualiu0"><span ismodified="1" class="br_wrap">[Code]</span></a> 
                    </td>
                  </tr>
				 			  

                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Viewport-Aware Adaptive Volumetric Video Streaming</span></strong> <br>
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Zihan Xu</span></a>,					  
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Wenyi Zhang</span></a>,
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,					  
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
                      <a href="https://scholar.google.com/citations?user=gxtzvm4AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Lian Zhao</span></a>,
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em>, 2022. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Ebublio: Edge Assisted Multi-user 360-Degree Video Streaming</span></strong> <br>
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Yili Jin</span></a>,
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://mypage.cuhk.edu.cn/academics/wangfangxin/index.html"><span ismodified="1" class="br_wrap">Fangxin Wang</span></a>, 
                      <a href="https://scholar.google.com/citations?user=1o_qvR0AAAAJ&hl=en"><span ismodified="1" class="br_wrap">Shuguang Cui</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      IEEE Conference on Virtual Reality and User Interfaces (</span><em><span ismodified="1" class="br_wrap">IEEE VR</span></em>), 2022. (Short paper)
                      <a href=""><span ismodified="1" class="br_wrap">[arXiv]</span></a>
                      <a href="https://junhualiu0.github.io"><span ismodified="1" class="br_wrap">[Project Page]</span></a>
                      <a href="https://github.com/junhualiu0"><span ismodified="1" class="br_wrap">[Code]</span></a> 
                    </td>
                  </tr>
				  
				  
                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <div class="one">
                        <img src="images/trans.png" width="80"></div>
                      </div>
                    </td>
                    <td style="padding:0px;width:78%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                      <strong><span ismodified="1" class="br_wrap">Improving the Generation Ability of Stock-trading Agents With Generated Samples</span></strong> <br>
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Biaolin Wen</span></a>,
					                        <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <a href="https://sds.cuhk.edu.cn/en/teacher/448"><span ismodified="1" class="br_wrap">Tianshu Yu</span></a>,
                      <a href="https://scholar.google.com/citations?user=WZNJufQAAAAJ&hl=en"><span ismodified="1" class="br_wrap">Bowen Zhang</span></a>,
                      <br><span ismodified="1" class="br_wrap">
                      </span><em><span ismodified="1" class="br_wrap">In submission</span></em>, 2022. <font color="red"><strong><span ismodified="1" class="br_wrap"></span></strong></font>
                      [arXiv]
                      [Project Page]
                      [Code]
                    </td>
                  </tr>
               </tbody>
              </table>

<!-- projects -->
	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-left:10px"><tbody>
			<heading id="projects" style="padding-left:20px">Projects</heading>
                  <tr>
                    <td style="padding:0px;width:13%;vertical-align:middle;padding-top:0px;padding-bottom:4px;padding-left:10px">
                        <img src="images/trans.png" width="80">
                    </td>
                    <td style="padding:0px;width:85%;vertical-align:middle;padding-top:0px;padding-bottom:0px;padding-left:10px">
                      <strong>NeRS: A network-based Reinforced system for Embodied Intelligence</strong>
                      <br>
                      <strong><span ismodified="1" class="br_wrap">Junhua Liu</span></strong>, 
                      <br><span ismodified="1" class="br_wrap">
                      Project on DDA4230: Reinforcement Learning, 2022. 
                      [arXiv]
                      <a href="https://junhualiu0.github.io/ners/"><span ismodified="1" class="br_wrap">[Project Page]</span></a>
                      <a href="https://github.com/ners"><span ismodified="1" class="br_wrap">[Code]</span></a> 
                    </td>
                  </tr>
				<br>
               </tbody>
              </table>
			  


<table>
<tbody>
<heading id="experience" style="padding-left:20px">Experience</heading>
<tr>
  <td width="730" style="padding-left:20px"><a href="https://aws.amazon.com/ai/"><b>Future Network of Intelligence Institute</b></a> (Dec. 2021 - Now)<br>
  Research Assistant, Intelligent Networking and Multimedia Lab<br>
</td>
<td style="padding-right:20px">
	<img id="school_logo" src="./images/FNii.png" height="50px">
</td>
</tr> 
</tbody></table>

<table>
<tbody><tr>
  <td width="800" style="padding-left:20px"><a href="https://ailab.bytedance.com/"><b>SenseTime Technology</b></a>, China (Aug. 2022 - Now)<br>
  Research Intern, ISP&Codec Group<br>
</td>
<td style="padding-right:20px">
	<img id="school_logo" src="./images/logo (2).png" height="50px" width="80px">
</td>  
</tr>
</tbody></table>

<table>
<tbody><tr>
  <td width="720" style="padding-left:20px"><a href="https://aws.amazon.com/ai/"><b>Harvard University</b></a> (Mar. 2022 - Jun. 2022)<br>
  Research Assistant, CAMLab<br>
</td>
<td style="padding-right:17px">
	<img id="school_logo" src="./images/Harvard-Logo-500x423.png" height="50px">
</td>  
</tr></table>

<table>
<tbody><tr>
  <td width="800" style="padding-left:20px"><a href="https://ailab.bytedance.com/"><b>AIRS</b></a>, Shenzhen (Jan. 2022 - Feb. 2022<br>
  Research Intern, Student Robotics Association and NLP Project<br>
</td>
<td style="padding-right:20px">
	<img id="school_logo" src="./images/AIRS (2).png" height="50px" width="80px">
</td>  
</tr></table>
			  
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<tbody><tr>
<td style="padding:20px;width:100%;vertical-align:middle">
  <heading>Awards</heading>
      <ul>  
		<li>
			Admission scholarship(Top 800 in College Entrance Examination)</li>      
		<li>
			Bowen Scholarship II(top 0.25% province-wide)</li>     
        <li>
          Undergraduate Research Award(Top 8% in the school)</li>
		 <li>
          2022 Shaw Overcoming Award(Only 3 in the school)</li>   
      </ul>
  <heading>Academic Service</heading>
      <ul>  
		<li>
			<b>Conference review: </b>ICASSP 2023, IEEE VR 2023 </li>      
		<li>
			<b>Journal review: </b>To be updated</li>        
      </ul>
	  
  <heading>Teaching</heading>
      <ul>
		<li> To be updated</li>	  
      </ul>
  <heading id="talks" >Talks</heading>
	<ul>
	  <li><strong>Latex tutorial for academic applications</strong> <a href="https://youtu.be/yOk63LWbkqk"><i class="fa fa-video-camera" aria-hidden="true"></i></a> <a href="files/talks/HCL-MLIR-ODM-Aug11-2022.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a><br>
		<font color="gray"><a href="https://mp.weixin.qq.com/s/A42yJBIUJ_CWFEIOt8T_xQ">The School of Data Science Student Club </a>, Apr 11, 2022</font>
	  </li>
	  <li><strong>Special issue on video streaming</strong> <a href="https://youtu.be/yOk63LWbkqk"><i class="fa fa-video-camera" aria-hidden="true"></i></a> <a href="files/talks/HCL-MLIR-ODM-Aug11-2022.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a><br>
		<font color="gray"><a href="files/talk1.pdf">Sensetime Research </a>, Aug 23, 2022</font>
	  </li>	 
	  <li><strong>Novel view synthesis</strong> <a href="https://youtu.be/yOk63LWbkqk"><i class="fa fa-video-camera" aria-hidden="true"></i></a> <a href="files/talks/HCL-MLIR-ODM-Aug11-2022.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i></a><br>
		<font color="gray"><a href="files/talk2.pdf">The Chinese University of Hongkong, shenzhen </a>, Oct 12, 2022</font>
	  </li>	 	  
	</ul>
<heading id="mis">Miscellaneous</heading>
		<ul>
		<details><summary>Some of my friends(random order):</summary> 
		  <!--<img id='school_logo' src="./images/braveheart1.jpeg" border="0" width="250">-->
		  <i>Huazhong University of Science and Technology:</i> 
		  <a href="http://quwenjie.github.io/"  target="_blank">Wenjie Qu</a>, <a href="https://mfp0610.github.io/"  target="_blank">Fanpeng Meng</a>, <a href="https://sherlyhu00.github.io/yhu.github.io/"  target="_blank">Yirui Hu</a>
		  <i>Fudan University:</i>
		  <a href="https://baidu.com"  target="_blank">Dengyu Yang</a>
		  <br>
		  <i>Tsinghua University:</i> 
		  <a href="https://zhaochenyang20.github.io/"  target="_blank">Chenyang Zhao</a>
		  ;
		  <i>Xi’an Jiaotong University:</i> 
		  <a href="https://qiaolin-yu.github.io/"  target="_blank">Qiaolin Yu</a>
		  ;
		  <i>Peking University:</i> 
		  <a href="http://whilebug.github.io/"  target="_blank"></a>
		  <br>
		  <i>Shanghai Jiao Tong University:</i> 
		  <a href="https://yanjieze.com/"  target="_blank">Yanjie Ze</a>
		  ;
		  <i>Si Chuan University:</i> 
		  <a href="http://whilebug.github.io/"  target="_blank">Peiran Wang</a>, <a href="https://zoedsy.github.io/"  target="_blank">Shiyi Du</a>
		  ;
		  <i>University of Southern California:</i>
		  <a href="https://boese0601.github.io"  target="_blank">Di Chang</a>;
		  <i>Shandong University:</i> 
		  ;
		  <a href="https://qitaozhao.github.io/"  target="_blank">Qitao Zhao</a>
  		  <i>CUHKSZ:</i> 
		  <a href="https://qitaozhao.github.io/"  target="_blank">Tianci Hou</a>
		  ;
		  <i>The Hong Kong Polytechnic University:</i> 
		  <a href="https://zhe-wang0018.github.io/"  target="_blank">Zhe Wang</a>
		  ;
  		  <i>University of Maryland:</i> 
		  <a href="https://haomingcai.com/"  target="_blank">Haoming Cai</a>
		  ;
		  <i>BUPT:</i> 
		  <a href="https://leiyu0210.github.io/"  target="_blank">Yu Lei</a>
		  <br>
		  <br><br>		  
		</details>
		<li>
			🐶Dog, 🎧pop music and 📷photography lover.</li>		  
		<li>
			🏸Badminton, 🚴‍♂Mountain cycling,🤽‍♂️Swimming,🎯Archery, 🥌Curling.<br> Member of serveral sports team.</li>
		<li>
			🍕🍮Baking, dessert. 🎮Video Games.</li>
		</ul>
  	<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            </td>
          </tr>
	</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		<div align="center">
		  <small>This page has been visited for
			<a href="https://www.easycounter.com/">
			<img src="https://www.easycounter.com/counter.php?double" border="0" alt="Free Hit Counters"></a> Times.
		  </div> <p>
	<center>
	<div align="center" style="width:20%">
	  <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=grr8tSJTdsbdU-vHO6Of-5W7jpLTZvSVYTu6BUgf02M"></script>
	</div></center></p>
	
	<!-- <p align="center"><font color="#999999">Last update: Oct. 28, 2022</font></p> -->
	</tbody></table>
	

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
</tbody></table>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
</tbody></table>
</table>	
</body>

</html>
